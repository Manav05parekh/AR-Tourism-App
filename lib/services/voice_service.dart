import 'dart:convert';
import 'dart:io';
import 'package:flutter_tts/flutter_tts.dart'; // backup TTS
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter/foundation.dart';

class VoiceService {
  // üéôÔ∏è Speech & Audio
  final stt.SpeechToText _speech = stt.SpeechToText();
  final AudioPlayer _player = AudioPlayer();
  final FlutterTts _fallbackTts = FlutterTts();

  // üîë API Keys
  final String geminiApiKey = "AIzaSyB5Edx_8VwOvLmviwgAPNpmtbaj1eSvToA";
  final String elevenLabsApiKey = "sk_5d7069e9ea1deab6aa955c02e84a5156a541929a9a2567c2"; // put your key
  final String elevenVoiceId = "4BoDaQ6aygOP6fpsUmJe";
  final String geminiModel = "gemini-2.0-flash";

  // ‚úÖ Detect if text is Hindi
  bool _isHindi(String text) {
    final hindiRegex = RegExp(r'[\u0900-\u097F]+');
    return hindiRegex.hasMatch(text);
  }

  // üéß ElevenLabs speech
  Future<void> speakWithElevenLabs(
    String text, {
    double rate = 1.0,
    bool isHindi = false,
    VoidCallback? onStart,
    VoidCallback? onEnd,
  }) async {
    onStart?.call();
    final voiceId = elevenVoiceId;
    final uri = Uri.parse("https://api.elevenlabs.io/v1/text-to-speech/$voiceId");

    final body = jsonEncode({
      "text": text,
      "model_id": "eleven_multilingual_v2",
      "voice_settings": {
        "stability": 0.15,
        "similarity_boost": 0.85,
        "style": rate.clamp(0.5, 1.5),
        "use_speaker_boost": true
      }
    });

    try {
      final response = await http.post(
        uri,
        headers: {
          "Accept": "audio/mpeg",
          "Content-Type": "application/json",
          "xi-api-key": elevenLabsApiKey,
        },
        body: body,
      );

      if (response.statusCode == 200 &&
          (response.headers['content-type']?.contains('audio') ?? false)) {
        final dir = await getTemporaryDirectory();
        final file = File("${dir.path}/tts_output.mp3");
        await file.writeAsBytes(response.bodyBytes);

        await _player.stop();
        await _player.play(DeviceFileSource(file.path), mode: PlayerMode.lowLatency);
        _player.onPlayerComplete.listen((_) => onEnd?.call());
      } else {
        print("‚ùå ElevenLabs error: ${response.body}");
        await _fallbackTts.speak(text);
        onEnd?.call();
      }
    } catch (e) {
      print("‚ö†Ô∏è ElevenLabs exception: $e");
      await _fallbackTts.speak(text);
      onEnd?.call();
    }
  }

  // üé§ Long-duration speech recognition (Hindi + English)
  Future<String?> listenUserSpeech({
    Duration maxDuration = const Duration(seconds: 60),
    String initialLocale = "en-IN",
  }) async {
    bool available = await _speech.initialize(
      onError: (err) => print("‚ö†Ô∏è Speech error: $err"),
      onStatus: (status) => print("üéß Status: $status"),
    );

    if (!available) {
      print("‚ùå Speech recognition unavailable");
      return null;
    }

    String finalResult = "";
    bool isListening = true;

    // Listen in English first
    await _speech.listen(
      listenFor: maxDuration,
      pauseFor: const Duration(seconds: 3),
      partialResults: true,
      localeId: initialLocale,
      onResult: (result) {
        final text = result.recognizedWords.trim();
        if (text.isNotEmpty) {
          finalResult = text;
        }
      },
    );

    // Wait until listening finishes
    final start = DateTime.now();
    while (isListening && DateTime.now().difference(start) < maxDuration) {
      await Future.delayed(const Duration(milliseconds: 500));
      if (!_speech.isListening) {
        isListening = false;
      }
    }

    await _speech.stop();

    // If empty or Hindi detected ‚Üí try Hindi mode
    if (finalResult.isEmpty || _isHindi(finalResult)) {
      print("üîÅ Switching to Hindi recognition...");
      finalResult = "";
      await _speech.listen(
        listenFor: maxDuration,
        pauseFor: const Duration(seconds: 3),
        partialResults: true,
        localeId: "hi-IN",
        onResult: (result) {
          final text = result.recognizedWords.trim();
          if (text.isNotEmpty) {
            finalResult = text;
          }
        },
      );

      final start2 = DateTime.now();
      bool listeningHindi = true;
      while (listeningHindi && DateTime.now().difference(start2) < maxDuration) {
        await Future.delayed(const Duration(milliseconds: 500));
        if (!_speech.isListening) {
          listeningHindi = false;
        }
      }
      await _speech.stop();
    }

    print("üéôÔ∏è Final Speech Result: $finalResult");
    return finalResult.isNotEmpty ? finalResult : null;
  }

  // üß† Get Gemini reply
  Future<String> getGeminiReply(String query, {bool detailed = false}) async {
    final isHindi = _isHindi(query);

    final tonePrompt = isHindi
        ? "‡§§‡•Å‡§Æ ‡§è‡§ï ‡§¶‡•ã‡§∏‡•ç‡§§‡§æ‡§®‡§æ ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£ ‡§µ‡§∞‡•ç‡§ö‡•Å‡§Ö‡§≤ ‡§ó‡§æ‡§á‡§° ‡§π‡•ã‡•§"
        : "You are a friendly and knowledgeable virtual tour guide.";

    final stylePrompt = detailed
        ? (isHindi
            ? "‡§â‡§§‡•ç‡§§‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§î‡§∞ ‡§∞‡•ã‡§ö‡§ï ‡§¶‡•ã‡•§"
            : "Give a detailed, engaging answer.")
        : (isHindi
            ? "‡§â‡§§‡•ç‡§§‡§∞ ‡§õ‡•ã‡§ü‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¶‡•ã‡•§"
            : "Give a short and clear answer.");

    final langPrompt = isHindi ? "‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¶‡•ã‡•§" : "Reply only in English.";

    final prompt = "$tonePrompt\n$stylePrompt\n$langPrompt\nUser said: \"$query\"";

    try {
      final response = await http.post(
        Uri.parse(
            "https://generativelanguage.googleapis.com/v1beta/models/$geminiModel:generateContent?key=$geminiApiKey"),
        headers: {"Content-Type": "application/json"},
        body: jsonEncode({
          "contents": [
            {"role": "user", "parts": [{"text": prompt}]}
          ]
        }),
      );

      final data = jsonDecode(response.body);
      final reply = data["candidates"]?[0]?["content"]?["parts"]?[0]?["text"];

      return reply ??
          (isHindi ? "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•à‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§∏‡§Æ‡§ù ‡§™‡§æ‡§Ø‡§æ‡•§" : "Sorry, I didn‚Äôt catch that.");
    } catch (e) {
      print("‚ö†Ô∏è Gemini API error: $e");
      return isHindi ? "‡§ï‡•Å‡§õ ‡§ó‡§°‡§º‡§¨‡§°‡§º ‡§π‡•ã ‡§ó‡§à‡•§" : "Something went wrong.";
    }
  }

  // üéµ Intro audio
  Future<void> playIntroAudio() async {
    await speakWithElevenLabs(
      "Hey there! I'm your virtual guide today ‚Äî ready for an awesome tour?",
    );
  }

  void dispose() {
    _player.dispose();
    _fallbackTts.stop();
  }
}
